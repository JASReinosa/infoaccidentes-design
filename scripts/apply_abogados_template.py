
import os
import re
from bs4 import BeautifulSoup
import glob

TEMPLATE_FILE = "abogados_provincia.html"
TARGET_DIR_PATTERN = "abogados-trafico/*/index.html"

def standardize_pages():
    # 1. Load the Template
    try:
        with open(TEMPLATE_FILE, "r", encoding="utf-8") as f:
            template_html = f.read()
    except FileNotFoundError:
        print(f"Error: Template file {TEMPLATE_FILE} not found.")
        return

    # 2. Iterate through target files
    files = glob.glob(TARGET_DIR_PATTERN)
    print(f"Found {len(files)} files to process.")

    for file_path in files:
        print(f"Processing: {file_path}")
        
        # Load Existing Page Content
        with open(file_path, "r", encoding="utf-8") as f:
            source_html = f.read()
        
        source_soup = BeautifulSoup(source_html, "html.parser")
        
        # --- EXTRACTION ---
        
        # Extract Title
        title_tag = source_soup.title
        title_text = title_tag.string if title_tag else "Abogados de Accidentes"
        
        # Extract Meta Description
        meta_desc = source_soup.find("meta", attrs={"name": "description"})
        meta_desc_content = meta_desc["content"] if meta_desc else ""
        
        # Extract H1 (Hero Title)
        h1_tag = source_soup.find("h1")
        h1_text = h1_tag.get_text().strip() if h1_tag else title_text
        
        # Determine City Name from H1
        # Expecting "Abogados de Accidentes de Tráfico en [City]"
        city_name = "Cantabria" # Default
        match = re.search(r"en\s+(.*?)$", h1_text, re.IGNORECASE)
        if match:
            city_name = match.group(1).split("|")[0].strip() # Handle cases like "en City | Info"
        else:
            # Fallback to H1 itself if "en" not found, or maybe directory name text
            city_name = h1_text
            
        # Extract Main Content
        # We want to get everything from the 'main' tag or equivalent wrapper.
        # But we want to exclude the H1 since we handle it specifically.
        # The previous generation script put content in `main > div.prose`
        source_main = source_soup.find("main")
        migrated_content_nodes = []
        
        if source_main:
            # Look for the prose container if generated by previous script
            prose_container = source_main.find("div", class_="prose")
            content_root = prose_container if prose_container else source_main
            
            # Copy children but FILTER OUT known template sections to avoid duplication on re-runs
            # We only want the "Introduction" and the "Lawyer List"
            # Known template headers to skip (partially matching)
            SKIP_HEADERS = [
                "Problemas comunes",
                "Por qué elegir InfoAccidentes",
                "Tipos de Accidentes",
                "Indemnización por Lesiones",
                "Historias de éxito",
                "Preguntas Frecuentes",
                "Consulta Gratuita",
                "Información sobre Accidentes en" # The header we added ourselves last time
            ]
            
            for child in content_root.contents:
                if child.name == "h1":
                    continue
                
                # Check if this node is a section/div/h* that corresponds to a template part
                text_content = child.get_text() if child.name else str(child)
                
                # If it's a tag, check its headers
                should_skip = False
                if child.name:
                    # Check direct headers inside
                    for header in child.find_all(['h2', 'h3', 'h4']):
                        if any(skip in header.get_text() for skip in SKIP_HEADERS):
                            should_skip = True
                            break
                    # Check text immediately if it's a header itself
                    if child.name in ['h2', 'h3', 'h4']:
                        if any(skip in child.get_text() for skip in SKIP_HEADERS):
                            should_skip = True
                
                if should_skip:
                    continue
                    
                migrated_content_nodes.append(child)
        else:
            print(f"Warning: No <main> found in {file_path}")

        # --- PREPARE NEW PAGE ---
        
        template_soup = BeautifulSoup(template_html, "html.parser")
        
        # 1. Update Title & Meta
        if template_soup.title:
            template_soup.title.string = title_text
        
        template_meta = template_soup.find("meta", attrs={"name": "description"})
        if template_meta:
            template_meta["content"] = meta_desc_content
            
        # 2. Localize Template Text
        # Replace "Cantabria" and ensuring specific Cantabrian cities are mapped to the new City Name
        # to avoid "Santander, A Coruña" inconsistencies.
        
        target_replacements = {
            "Cantabria": city_name,
            "Santander": city_name,
            "Torrelavega": city_name,
            "Laredo": city_name,
            "Castro Urdiales": city_name,
            "Reinosa": city_name,
            "Peña Cabarga": "una zona complicada",
            "Picos de Europa": "la sierra"
        }

        # Helper to apply replacements to a string
        def apply_replacements(text):
            if not text: return text
            for original, verification in target_replacements.items():
                if original in text:
                    text = text.replace(original, verification)
            return text

        # A. Replace in Text Nodes
        for text_node in template_soup.find_all(string=True):
            if text_node.parent.name in ['script', 'style']:
                continue
            new_text = apply_replacements(text_node)
            if new_text != text_node:
                text_node.replace_with(new_text)

        # B. Replace in Attributes (alt, title, etc.)
        target_attrs = ['title', 'alt', 'placeholder', 'aria-label', 'content', 'data-alt']
        for tag in template_soup.find_all(True): # All tags
            for attr in target_attrs:
                if tag.has_attr(attr):
                    val = tag[attr]
                    if isinstance(val, str):
                        new_val = apply_replacements(val)
                        if new_val != val:
                            tag[attr] = new_val
                            # print(f"replaced attr {attr} in {tag.name}: {val} -> {new_val}")

        # 3. Update Hero H1
        template_h1 = template_soup.find("h1")
        if template_h1:
            # Reconstruct H1: "Abogados Especialistas ... en [City]"
            # We want to maintain the styling: text-dark ... <span class="text-primary">City</span>
            template_h1.clear()
            template_h1.append("Abogados Especialistas en Accidentes de Tráfico en ")
            span = template_soup.new_tag("span", attrs={"class": "text-primary"})
            span.string = city_name + ": Reclame su Máxima Indemnización" # Matches the H1 from CSV or just City?
            # actually H1 in template is long. Let's just use the city name for the span?
            # User wants "match the name of each location".
            # If h1_text is provided, use it.
            # But we want to style the City part.
            
            # Simple approach: Use full h1_text, but try to highlight the city if possible.
            # Or just set it plain.
            template_h1.string = h1_text 

        # 4. Inject Migrated Content
        # Target: <article class="prose-content">
        template_article = template_soup.find("article", class_="prose-content")
        
        if template_article:
            # Create a divider/header for migrated content
            divider = template_soup.new_tag("div", attrs={"class": "my-12 border-t border-slate-200"})
            template_article.append(divider)
            
            migrated_section_title = template_soup.new_tag("h2")
            migrated_section_title.string = f"Información sobre Accidentes en {city_name}"
            template_article.append(migrated_section_title)
            
            # Append extracted nodes
            for node in migrated_content_nodes:
                # Need to use copy to avoid issues with moving nodes betwen soups?
                # BS4 handles this usually, but let's be safe
                import copy
                node_copy = copy.copy(node)
                template_article.append(node_copy)
        else:
             print("Error: Could not find <article class='prose-content'> in template")
             
        # 4b. Fix Relative Paths
        # Since we are saving toogados-trafico/[city]/index.html, we are 2 levels deep.
        # We need to update local links and assets to use ../../
        
        def fix_path(path):
            if not path: return path
            # Ignore absolute URLs, anchors, mailto, etc.
            if path.startswith(("http", "//", "#", "mailto:", "tel:")):
                return path
            # If it's already relative with ../, skip or handle (assuming template is simple)
            if path.startswith("../"):
                return path # Already relative?
            return "../../" + path

        for tag in template_soup.find_all(['a', 'link'], href=True):
            tag['href'] = fix_path(tag['href'])
            
        for tag in template_soup.find_all(['script', 'img'], src=True):
            tag['src'] = fix_path(tag['src'])

        # 5. Save File
        with open(file_path, "w", encoding="utf-8") as out_f:
            out_f.write(str(template_soup.prettify()))
        
        print(f"Updated: {file_path}")

if __name__ == "__main__":
    standardize_pages()
